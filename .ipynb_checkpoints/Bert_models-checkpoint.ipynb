{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af78b4ab",
   "metadata": {},
   "source": [
    "#Â Machine learning models for Name-Entity-Recgnition\n",
    "Summary of the paper [https://arxiv.org/abs/1812.09449]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164562a2",
   "metadata": {},
   "source": [
    "The goal is to summarize machine learning algorithms used so far to tackle N.E.R tasks. The corresponding models vary from earlier ones to state-of-art models such as Generative adversarial Network, Transformers, Reinforcement learning etc...  . Then, we propose an implementation of the models and compare their performance on a N.E.R dataset taken from \"kaggle\". \n",
    "\n",
    "The idea behind this undeavor is to go in depth on the architecture of N.E.R models, so that we will be able to make educative decision on to what model to choose given a particular dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268e3ac9",
   "metadata": {},
   "source": [
    "### What is Name Entity Recognition? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4ca051",
   "metadata": {},
   "source": [
    "Name-Entity-Recognition(N.E.R) consists in associating entities(semantic types) to words in sentence. The entities could be: person, organisation, location, etc...  N.E.R plays an essential role in a variety of natural language processing applications such as information retrieval, automatic text summarization, question answering, machine translation, knowledge base contruction etc... "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aed6210",
   "metadata": {},
   "source": [
    "### N.E.R techniques "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365012a8",
   "metadata": {},
   "source": [
    "Name entities are generally classfied in two categories : `generic NEs` (eg: person and location) and `domain-specific NEs` (e.g: protein, enzymes, and genes). The focus here will be on generic english based NEs.\n",
    "\n",
    "As to the `techniques` applied in NER, there are four main streams: \n",
    "\n",
    "- Rule-based approaches : Which do not need annotated data as they rely on hand-crafted rules;\n",
    "\n",
    "- Unsupervised learning approches : which rely on unsupervised learning approches without hand-labeled training samples;\n",
    "\n",
    "- Feature-based supervised learning approches: which rely on supervised learning algorithms ;\n",
    "\n",
    "- Deep-learning based approaches: which automatically discover representations needed for the classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bf96d2",
   "metadata": {},
   "source": [
    "### The Structure of the Paper. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e10684",
   "metadata": {},
   "source": [
    "- 1. Background:  definition , resources , evaluation metrics, and traditional approaches of NER;\n",
    "\n",
    "- 2. Deep learning techniques for NER; \n",
    "\n",
    "- 3. Summarizes recent applied deep learning techniques; \n",
    "\n",
    "- 4. Implementation of the models;\n",
    "\n",
    "- 5. Challenges and misconceptions. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5576df88",
   "metadata": {},
   "source": [
    "#### 1 - Background\n",
    "\n",
    "Before delving into the how deep learning is used in NER field, we first explain the NER concept. We then introduce the widely used `NER datasets and tools`. Next, we detail the evaluation metrics and summarize the traditional approaches to NER .  \n",
    "\n",
    "An illustration of the `Named-entity-Recognition task`:\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"images/N.E.R\" height=40, width=400> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7861bde8",
   "metadata": {},
   "source": [
    "#### 1.1 N.E.R \n",
    "See above for more detail . "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a296c64d",
   "metadata": {},
   "source": [
    "##### 1.2 NER Resources :Datasets and tools \n",
    "\n",
    "Here is presented the widely used datasets and off-the-shelf tools for English NER.\n",
    "\n",
    "In table1 are presented some of the annotated corpus used for training NER models.  \n",
    "\n",
    "<img src=\"images/corpus\" height=50, width=500> \n",
    "\n",
    "In table2 are presented some of the tools used to annotate corpus . \n",
    "\n",
    "<img src=\"images/tools\" height=50, width=500> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b37dde5",
   "metadata": {},
   "source": [
    "#### 1.3 NER Evaluation Metrics "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ffb7d6",
   "metadata": {},
   "source": [
    "NER models are usually evaluated by comparing their outputs against human annotations. The comparison can quantify either as `exact-match` or `relaxed match`. \n",
    "\n",
    "1.3.1 `Exact-match Evaluation`\n",
    "\n",
    "NER involves identifying both entity boundaries and entity types. In `Exact math Evaluation`, a name entity is considered to be correctly recognized if both its boundary and type match ground truth. The performance metrics `Precision, Recall , F-score` are computed on the number of `True positives(TP), False Positive(FP), False Negatives (FN)`. \n",
    "\n",
    "- `TP` : entities recognised by the NER and match the ground truth.  \n",
    "- `FP` : entities recgonised by the NER but not match the ground truth \n",
    "- `FN` : entities not recgonised by the NER but annotated in the ground truth .  \n",
    "\n",
    "\n",
    "**Precision** = Among the outputs recognized as entities what is the proportion matching the ground truth. It measures the ability to present correct entities  = $$\\frac{TP}{TP + FP}$$ \n",
    "\n",
    "**Recall** = measures the ability to recognize all entities in the corpus $$\\frac{TP}{TP+FN}$$\n",
    "\n",
    "**F-score** = harmonic mean between Recall and Precision= $$2\\times{\\frac{Precision\\times Recall}{Precision + Recall}}$$\n",
    "\n",
    "\n",
    "1.3.2 `Relaxed-match Evaluation`: \n",
    "\n",
    "A well known definition of `Relaxed-match evaluation` is that it consideres an entity as true if its type matches with that of the ground truth regarless of the boundaries as long as the latter overlaps with the ground truth boundaries. \n",
    "\n",
    "2.4 `Traditional Approaches to NER:`\n",
    "\n",
    "Traditional approaches to NER include : `rule-based approaches`, `unsupervised learning approches`, and `feature-based supervised learning approaches`. \n",
    "\n",
    "- Rule-based approaches : \n",
    "They are mainly hand-crafted based approaches. Some examples include: LaSIE, NetOwl, Facile, SAR, FASTUS, and LTG systems. The Rule based systems work very well when lexicon is exhaustive. With incomplete dictionaries, it leads to high precision and low recall . \n",
    "\n",
    "- Unsupervised Learning Approaches : \n",
    "A typical approach of unsupervised learning is clustering-based NER. The key idea is that **lexical patterns, lexical ressources and statistics** computed on a large corpus can be used to infer mentions of named entities. \n",
    "\n",
    "\n",
    "- Feature-based Supervised Learning Approaches : \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cfe8ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
